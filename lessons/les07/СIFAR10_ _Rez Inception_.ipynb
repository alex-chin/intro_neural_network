{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "СIFAR10 + Rez+Inception .ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah7dy1kFL2H9"
      },
      "source": [
        "# Распознавание объектов на изображениях \n",
        "\n",
        "Чтобы запускать и редактировать код, сохраните копию этого ноутбука себе (File->Save a copy in Drive...). Свою копию вы сможете изменять и запускать.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0pyYuxbg0wK"
      },
      "source": [
        "Грузим библиотеки :\n",
        "точно нужны слои,  optimizer , cifar10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivmw9St3nFnx"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import  BatchNormalization\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, Conv2D\n",
        "\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "%matplotlib inline \n",
        "\n",
        "from tensorflow.keras import utils\n",
        "# Количество классов изображений\n",
        "nb_classes = 10\n",
        "# Названия классов из набора данных CIFAR-10\n",
        "classes=['самолет', 'автомобиль', 'птица', 'кот', 'олень', 'собака', 'лягушка', 'лошадь', 'корабль', 'грузовик']\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "y_train10 = utils.to_categorical(y_train, nb_classes)\n",
        "\n",
        "y_test10 = utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "#x_train=np.broadcast_to(x_train[..., None],(60000,28,28,3))\n",
        "#x_test=np.broadcast_to(x_test[..., None],(10000,28,28,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlvKXPLWxT8s"
      },
      "source": [
        "from tensorflow.keras.layers import Add , Input,  Dense, Dropout, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
        "import tensorflow\n",
        "from tensorflow.keras.utils import plot_model,to_categorical\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odp_ZArlhTz9"
      },
      "source": [
        "задаем размер входа"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL9nxCJNy9lm"
      },
      "source": [
        "# Размер изображений  CIFAR10\n",
        "img_width, img_height, chanel_n = 32, 32, 3\n",
        "#img_width, img_height, chanel_n = 28, 28, 3\n",
        "\n",
        "print(x_train.shape)\n",
        "#пакет для генератора\n",
        "batch_size = 128\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwX8VwHKGgfx"
      },
      "source": [
        "#Свой классификатор "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDcjFVOaeMGf"
      },
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "layer_size = 10\n",
        "models = Sequential()\n",
        "# Добавляем в модель сеть VGG16 вместо слоя\n",
        "models.add(Conv2D(128,(3,3), activation='sigmoid',input_shape = (32,32,3))) # только свертка\n",
        "models.add(BatchNormalization())\n",
        "for i in range(layer_size):\n",
        "  models.add(Conv2D(128,(3,3), activation='sigmoid')) # только свертка\n",
        "  models.add(BatchNormalization())\n",
        "\n",
        "models.add(Flatten()) # векторим вход\n",
        "models.add(Dense(100,activation='sigmoid'))\n",
        "models.add(Dense(10,activation='softmax'))\n",
        "\n",
        "\n",
        "models.summary()\n",
        "\n",
        "\n",
        "print(models.layers[-1].input_shape)\n",
        "\n",
        "print(models.layers[-1].output_shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxV4zueVjQrr"
      },
      "source": [
        "Посмотрим, что вышло"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq7y-ngeNYQe"
      },
      "source": [
        "# компилияция модели\n",
        "models.compile(loss = 'categorical_crossentropy', optimizer = 'SGD', metrics = [\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to6ouJLaNrqc"
      },
      "source": [
        "hist = models.fit(x = x_train,y = y_train10, epochs = 1, batch_size = 128, validation_data = (x_test, y_test10), verbose = 1)\n",
        "\n",
        "test_score = models.evaluate(x_test, y_test10)\n",
        "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5goLguw0RoYA"
      },
      "source": [
        "\n",
        "predict1=models.predict(x_train[:20])\n",
        "print(predict1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6FRJqYsVwq0"
      },
      "source": [
        "Посмотрим , что распознается"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjfZMLmtSkgh"
      },
      "source": [
        "n=1\n",
        "\n",
        "plt.imshow(x_train[n][:,:,:])\n",
        "plt.title(classes[np.argmax(predict1[n,:])])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B24PXjO7TEww"
      },
      "source": [
        "predict1_test=models.predict(x_test[:20])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulRE-2L7T9U6"
      },
      "source": [
        "Сделаем немного тестов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdYSNCyGTjXk"
      },
      "source": [
        "n=5\n",
        "\n",
        "plt.imshow(x_test[n][:,:,:])\n",
        "plt.title(classes[np.argmax(predict1_test[n,:])])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym8k1LI-xMLD"
      },
      "source": [
        "\n",
        "# Создадим экземпляр оптимизатора. \n",
        "optimizer = tensorflow.keras.optimizers.SGD(learning_rate = 1e-3) \n",
        "# Instantiate a loss function. \n",
        "loss_fn = tensorflow.keras.losses.MeanSquaredError() #берем, т.к. виднее изменения(from_logits=True) \n",
        "# Подготовим тренировочный датасет. \n",
        "batch_size = 64 \n",
        "epochs=2  # учим немного, т.к. задача посмотреть , что происходит с градиентом\n",
        "train_dataset = tensorflow.data.Dataset.from_tensor_slices((x_train[:1000,:,:,:], to_categorical(y_train[:1000,0]))) \n",
        "train_dataset = train_dataset.shuffle(buffer_size = 1024).batch(batch_size) \n",
        "\n",
        "def my_train(model=None, epochs=None,batch_size=64,train_dataset=train_dataset ):\n",
        "  # Итерируем по эпохам.\n",
        "  grad_log=[]\n",
        "  w_log=[]\n",
        "\n",
        "\n",
        "  for epoch in range(epochs): \n",
        "    print('Начинаем эпоху %d' % (epoch,)) \n",
        "    # Итерируем по пакетам в датасете. \n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset): \n",
        "      # Откроем GradientTape чтобы записать операции # выполняемые во время прямого прохода, \n",
        "      #включающего автодифференцирование. \n",
        "      with tensorflow.GradientTape() as tape: \n",
        "        # Запустим прямой проход слоя. \n",
        "        # Операции применяемые слоем к своим \n",
        "        # входным данным будут записаны \n",
        "        # на GradientTape. \n",
        "        logits = model(x_batch_train) \n",
        "        # Logits для пакета  - выходы модели \n",
        "        # Вычислим значение потерь для этого пакета. \n",
        "        y_s=y_batch_train.numpy().shape\n",
        "        y  = tensorflow.reshape( y_batch_train,shape = (y_s[0],10,1))\n",
        "        l = tensorflow.reshape( logits,shape = (y_s[0],10,1))\n",
        "        # вызываем лосс\n",
        "        loss_value = loss_fn(y, l) \n",
        "        # Используем gradient tape для автоматического извлечения градиентов \n",
        "        # обучаемых переменных относительно потерь. \n",
        "        grads = tape.gradient(loss_value, model.trainable_weights) \n",
        "        g_g = []\n",
        "        w_w = []\n",
        "        # пишем логи для сохранения значений градиента по одному ядру из слоя (осредняем по абсолютным значениям) и \n",
        "        # веса по одной цепи (0-й канал распространения активности)\n",
        "        for g_s in grads:\n",
        "          if len(g_s.numpy().shape) == 1:\n",
        "         \n",
        "            g_g.append(g_s.numpy()[0])\n",
        "          if len(g_s.numpy().shape) == 2:\n",
        "          \n",
        "            g_g.append(np.mean(np.abs((g_s.numpy()[:,0])))) \n",
        "          if len(g_s.numpy().shape) == 3:\n",
        "          \n",
        "            g_g.append(np.mean(np.abs(g_s.numpy()[:,:,0]))) \n",
        "          if len(g_s.numpy().shape) == 4:\n",
        "          \n",
        "            g_g.append(np.mean(np.abs(g_s.numpy()[:,:,0,0])) ) \n",
        "\n",
        "        for w_s in model.trainable_weights:\n",
        "          if len(w_s.numpy().shape) == 1:\n",
        "            w_w.append(w_s.numpy()[0])\n",
        "          if len(w_s.numpy().shape) == 2:\n",
        "            w_w.append(w_s.numpy()[0,0])\n",
        "          \n",
        "          if len(w_s.numpy().shape) == 3:\n",
        "            w_w.append(w_s.numpy()[0,0,0])\n",
        "         \n",
        "          if len(w_s.numpy().shape) == 4:\n",
        "            w_w.append(w_s.numpy()[0,0,0,0])\n",
        "              \n",
        "        # добавляем текущие логи по слоям к общей записи\n",
        "        grad_log.append(g_g)\n",
        "        w_log.append(w_w)\n",
        "        # Выполним один шаг градиентного спуска обновив # значение переменных минимизирующих потери. \n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights)) \n",
        "        # Пишем лог каждые 1000 пакетов. \n",
        "        if step % 1000 == 0: \n",
        "          print('Потери на обучении (для одного пакета) на шаге %s: %s' % (step, float(loss_value))) \n",
        "          print('Уже увидели: %s примеров' % ((step + 1) * batch_size))\n",
        "  grad_log=np.array(grad_log)\n",
        "  w_log=np.array(w_log)\n",
        "  return grad_log, w_log, model, x_batch_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод значений градиента по слоям"
      ],
      "metadata": {
        "id": "_7urIdFkyAdg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVJALHfUx2Pz"
      },
      "source": [
        "def visual_grad(grad_log = None, numb_layer = -1):\n",
        "  s_g = grad_log.shape\n",
        "  grad_log = grad_log/np.max(grad_log,axis = 1).reshape((s_g[0],1))\n",
        "  #print(grad_log[0,:])\n",
        "  plt.figure(figsize = (16,5))\n",
        "  plt.title('Градиент по слоям')\n",
        "  plt.xlabel('№ layer')\n",
        "  plt.ylabel('grad')\n",
        "  plt.grid()\n",
        "  plt.plot(np.abs(grad_log[0,:numb_layer]),label='step 0')\n",
        "  plt.plot(np.abs(grad_log[s_g[0] // 10,:numb_layer]),label='step '+str(s_g[0] // 10))\n",
        "  plt.plot(np.abs(grad_log[s_g[0] // 3,:numb_layer]),label='step '+str(s_g[0] // 3))\n",
        "  plt.plot(np.abs(grad_log[s_g[0]-1 ,:numb_layer]),label='step  '+str(s_g[0] ))\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vi1HaIk2kzV"
      },
      "source": [
        "grad_log,w_log,models, x_batch_train = my_train( model = models, epochs = 1,batch_size = 10 , train_dataset = train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueqsBxKm3BZu"
      },
      "source": [
        "visual_grad(grad_log = grad_log, numb_layer = grad_log.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrBZFZEIw5bh"
      },
      "source": [
        "ПОстроим сложный блок (Rez-Inception)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDwQHDqSx-8U"
      },
      "source": [
        "inputs = Input(shape=(32,32,3), name='CIFAR10rez') \n",
        "\n",
        "x = Conv2D(64,3, activation = 'relu', name = 'conv_1')(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64,3, activation = 'relu', name = 'conv_2')(x) \n",
        "# можно добавлять блоки сверток, но следует следить за размером\n",
        "# padding ='valid' - размер выходов постепенно уменьшается \n",
        "#ResNet - блок\n",
        "x_shortcut = x # +x\n",
        "x = Conv2D(64,3, activation = 'relu', padding = 'same',name = 'conv_31')(x) # H\n",
        "x = Conv2D(64,3, activation = 'relu', padding = 'same',name = 'conv_41')(x) \n",
        "x = Add()([x, x_shortcut]) # F = H +x\n",
        "x = BatchNormalization()(x)\n",
        "# нелинейная трансформация и уменьшение размера в 2 раза\n",
        "x = MaxPool2D()(x) \n",
        "x_shortcut = x\n",
        "x = Conv2D(64,3, activation = 'relu', padding = 'same', name = 'conv_32')(x) \n",
        "x = Conv2D(64,3, activation = 'relu', padding = 'same', name = 'conv_42')(x)\n",
        "x = Add()([x, x_shortcut])\n",
        "x = BatchNormalization()(x)\n",
        "x_shortcut = x\n",
        "\n",
        "x = Conv2D(64,3, activation = 'relu', padding = 'same', name = 'conv_3')(x) \n",
        "x = Conv2D(64,3, activation = 'relu',  padding = 'same', name = 'conv_4')(x)\n",
        "x = Add()([x, x_shortcut])  \n",
        "x = MaxPool2D((2,2),(2,2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation = 'relu', name = 'dense_1')(x) \n",
        " \n",
        "\n",
        "outputs = Dense(10,activation = 'sigmoid' ,name = 'predictions')(x) \n",
        "model1 = Model(inputs = inputs, outputs = outputs) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFo1eaI60R13"
      },
      "source": [
        "plot_model(model1,to_file = 'model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iO7mXpbyMdP"
      },
      "source": [
        "grad_log,w_log,model1, x_batch_train = my_train( model = model1, epochs = 1,batch_size = 1000 , train_dataset = train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BouWnobtxqlk"
      },
      "source": [
        "visual_grad(grad_log = grad_log, numb_layer = grad_log.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "id": "z_rygvUd36Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj31dpFdykE0"
      },
      "source": [
        "from tensorflow.keras.layers import concatenate \n",
        "\n",
        "\n",
        "inputs = Input(shape = (32,32,3), name = 'cifar_inception') \n",
        "\n",
        "x = Conv2D(64,3, activation='relu', name='conv_1')(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64,3, activation='relu', name='conv_2')(x) \n",
        "# можно добавлять блоки сверток, но следует следить за размером\n",
        "# padding ='valid' - размер выходов постепенно уменьшается \n",
        "#Inception - блок\n",
        "x_shortcut = x\n",
        "x0 = Conv2D(64,1, activation='relu', padding='same',name='conv_131')(x) \n",
        "x1 = Conv2D(64,1, activation='relu', padding='same',name='conv_231')(x) \n",
        "x1 = Conv2D(64,5, activation='relu', padding='same',name='conv_341')(x1) \n",
        "x2 = Conv2D(64,1, activation='relu', padding='same',name='conv_431')(x) \n",
        "x2 = Conv2D(64,3, activation='relu', padding='same',name='conv_541')(x2) \n",
        "x3 = Conv2D(64,3, activation='relu', padding='same',name='conv_631')(x) \n",
        "x3 = Conv2D(64,1, activation='relu', padding='same',name='conv_741')(x3) \n",
        "x = concatenate([x0,x1,x2,x3],axis=-1)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64,3, activation='relu', padding='same', name='conv_ee32')(x) \n",
        "x = Add()([x, x_shortcut])\n",
        "# нелинейная трансформация и уменьшение размера в 2 раза\n",
        "x = MaxPool2D()(x) \n",
        "x_shortcut = x\n",
        "x = Conv2D(64,3, activation='relu', padding='same', name='conv_32')(x) \n",
        "x = Conv2D(64,3, activation='relu', padding='same', name='conv_42')(x)\n",
        "x = Add()([x, x_shortcut])\n",
        "x = BatchNormalization()(x)\n",
        "x_shortcut = x\n",
        "x = Conv2D(64,3, activation = 'relu', padding = 'same',name = 'conv_33')(x) \n",
        "x = Conv2D(64,3, activation = 'relu', padding = 'same',name = 'conv_43')(x)  \n",
        "x = Add()([x, x_shortcut])  \n",
        "x = BatchNormalization()(x)\n",
        "x_shortcut = x\n",
        "x = Conv2D(64,3, activation = 'relu', padding = 'same', name = 'conv_3')(x) \n",
        "x = Conv2D(64,3, activation = 'relu',  padding = 'same', name = 'conv_4')(x)\n",
        "x = Add()([x, x_shortcut])  \n",
        "x = MaxPool2D((2,2),(2,2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation = 'relu', name = 'dense_1')(x) \n",
        " \n",
        "\n",
        "outputs = Dense(10,activation = 'sigmoid' ,name = 'predictions')(x) \n",
        "model1 = Model(inputs = inputs, outputs = outputs) \n",
        "\n",
        "grad_log,w_log,model1, x_batch_train = my_train( model = model1, epochs = 1,batch_size = batch_size , train_dataset = train_dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLH3nnRB2Fgw"
      },
      "source": [
        "plot_model(model1,to_file='model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHvAQqCd13ym"
      },
      "source": [
        "visual_grad(grad_log=grad_log, numb_layer=grad_log.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiydaLdV2Tfb"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d7b6W7E1Umxg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}