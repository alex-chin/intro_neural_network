{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Практическое задание №7. Детектирование объектов\n",
    "\n",
    "\n",
    "1.   Обучите нейронную сеть любой архитектуры которой не было на курсе, либо обучите нейронную сеть разобранной архитектуры, но на том датасете, которого не было на уроках. Сделайте анализ, того, что вам помогло в улучшения работы нейронной сети.</li>\n",
    "\n",
    "\n",
    "*   *вариант для 1) Обучите VAE на fashion_mnist\n",
    "*   *вариант для 1) Обучите GAN на одном классе CIFAR\n",
    "*   *вариант для 1) обучите классификатор на данных tfds (Kaggle, UCI)\n",
    "*   *вариант для 1) обучите семантическую сегментацию на tfds (Kaggle, UCI)\n",
    "\n",
    "\n",
    "2.    Сделайте краткий обзор какой-нибудь научной работы посвященной тому или иному алгоритму нейронных сетей, который не рассматривался на\n",
    "курсе. Проведите анализ: Чем отличается выбранная вами на рассмотрение архитектура нейронной сети от других архитектур? В чем плюсы и минусы данной архитектуры? Какие могут возникнуть трудности при применении данной архитектуры на практике?\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, latent_dim=2, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.latent_dim = latent_dim\n",
    "        sampling = Sampling()\n",
    "        self.encoder=self.build_encoder(sampling)\n",
    "        self.decoder=self.build_decoder()\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction)\n",
    "            )\n",
    "            # todo to parameter\n",
    "            reconstruction_loss *= 28 * 28\n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *= -0.5\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "\n",
    "    def build_encoder(self, sampling):\n",
    "        encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "        x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "        x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dense(16, activation=\"relu\")(x)\n",
    "        z_mean = layers.Dense(self.latent_dim, name=\"z_mean\")(x)\n",
    "        z_log_var = layers.Dense(self.latent_dim, name=\"z_log_var\")(x)\n",
    "        z = sampling([z_mean, z_log_var])\n",
    "        encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "        return encoder\n",
    "\n",
    "    def build_decoder(self):\n",
    "        latent_inputs = keras.Input(shape=(self.latent_dim,))\n",
    "        x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "        x = layers.Reshape((7, 7, 64))(x)\n",
    "        x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "        x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "        decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "        decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "        return decoder\n",
    "\n",
    "    def get_decoder(self):\n",
    "        return self.decoder\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = keras.datasets.fashion_mnist.load_data()\n",
    "mnist_clothes = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_clothes = np.expand_dims(mnist_clothes, -1).astype(\"float32\") / 255"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 14, 14, 32)   320         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 7, 7, 64)     18496       ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 3136)         0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           50192       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 2)            34          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 2)            34          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 2)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 69,076\n",
      "Trainable params: 69,076\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3136)              9408      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        289       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,089\n",
      "Trainable params: 65,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vae = VAE()\n",
    "print(vae.get_encoder().summary())\n",
    "print(vae.get_decoder().summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "547/547 [==============================] - 51s 92ms/step - loss: 349.5983 - reconstruction_loss: 346.0529 - kl_loss: 3.5454\n",
      "Epoch 2/100\n",
      "547/547 [==============================] - 53s 96ms/step - loss: 311.6551 - reconstruction_loss: 307.2247 - kl_loss: 4.4304\n",
      "Epoch 3/100\n",
      "547/547 [==============================] - 53s 97ms/step - loss: 286.4610 - reconstruction_loss: 281.5074 - kl_loss: 4.9535\n",
      "Epoch 4/100\n",
      "547/547 [==============================] - 54s 99ms/step - loss: 277.1618 - reconstruction_loss: 272.1675 - kl_loss: 4.9943\n",
      "Epoch 5/100\n",
      "547/547 [==============================] - 54s 99ms/step - loss: 273.4350 - reconstruction_loss: 268.5346 - kl_loss: 4.9004\n",
      "Epoch 6/100\n",
      "547/547 [==============================] - 55s 100ms/step - loss: 271.0902 - reconstruction_loss: 266.2623 - kl_loss: 4.8278\n",
      "Epoch 7/100\n",
      "547/547 [==============================] - 55s 100ms/step - loss: 269.3872 - reconstruction_loss: 264.6191 - kl_loss: 4.7682\n",
      "Epoch 8/100\n",
      "547/547 [==============================] - 55s 100ms/step - loss: 268.0267 - reconstruction_loss: 263.3261 - kl_loss: 4.7006\n",
      "Epoch 9/100\n",
      "547/547 [==============================] - 52s 95ms/step - loss: 266.9454 - reconstruction_loss: 262.3285 - kl_loss: 4.6169\n",
      "Epoch 10/100\n",
      "547/547 [==============================] - 51s 93ms/step - loss: 266.0326 - reconstruction_loss: 261.4717 - kl_loss: 4.5610\n",
      "Epoch 11/100\n",
      "547/547 [==============================] - 52s 94ms/step - loss: 265.2929 - reconstruction_loss: 260.7899 - kl_loss: 4.5030\n",
      "Epoch 12/100\n",
      "547/547 [==============================] - 53s 97ms/step - loss: 264.6032 - reconstruction_loss: 260.1549 - kl_loss: 4.4484\n",
      "Epoch 13/100\n",
      "547/547 [==============================] - 60s 109ms/step - loss: 264.0099 - reconstruction_loss: 259.6371 - kl_loss: 4.3728\n",
      "Epoch 14/100\n",
      "547/547 [==============================] - 53s 98ms/step - loss: 263.3837 - reconstruction_loss: 259.0616 - kl_loss: 4.3221\n",
      "Epoch 15/100\n",
      "547/547 [==============================] - 52s 95ms/step - loss: 262.8799 - reconstruction_loss: 258.6271 - kl_loss: 4.2528\n",
      "Epoch 16/100\n",
      "547/547 [==============================] - 52s 94ms/step - loss: 262.6053 - reconstruction_loss: 258.4037 - kl_loss: 4.2016\n",
      "Epoch 17/100\n",
      "547/547 [==============================] - 52s 95ms/step - loss: 262.1474 - reconstruction_loss: 257.9805 - kl_loss: 4.1669\n",
      "Epoch 18/100\n",
      "547/547 [==============================] - 52s 95ms/step - loss: 261.6361 - reconstruction_loss: 257.5184 - kl_loss: 4.1178\n",
      "Epoch 19/100\n",
      "547/547 [==============================] - 52s 95ms/step - loss: 261.4901 - reconstruction_loss: 257.4048 - kl_loss: 4.0852\n",
      "Epoch 20/100\n",
      "547/547 [==============================] - 52s 95ms/step - loss: 260.9463 - reconstruction_loss: 256.8811 - kl_loss: 4.0653\n",
      "Epoch 21/100\n",
      "547/547 [==============================] - 52s 95ms/step - loss: 260.6580 - reconstruction_loss: 256.6125 - kl_loss: 4.0454\n",
      "Epoch 22/100\n",
      "547/547 [==============================] - 52s 96ms/step - loss: 260.4432 - reconstruction_loss: 256.4205 - kl_loss: 4.0227\n",
      "Epoch 23/100\n",
      "547/547 [==============================] - 53s 97ms/step - loss: 260.2597 - reconstruction_loss: 256.2558 - kl_loss: 4.0039\n",
      "Epoch 24/100\n",
      "547/547 [==============================] - 54s 98ms/step - loss: 259.9498 - reconstruction_loss: 255.9589 - kl_loss: 3.9909\n",
      "Epoch 25/100\n",
      "547/547 [==============================] - 57s 104ms/step - loss: 259.8065 - reconstruction_loss: 255.8361 - kl_loss: 3.9704\n",
      "Epoch 26/100\n",
      "547/547 [==============================] - 52s 95ms/step - loss: 259.4488 - reconstruction_loss: 255.4710 - kl_loss: 3.9778\n",
      "Epoch 27/100\n",
      "547/547 [==============================] - 52s 94ms/step - loss: 259.2467 - reconstruction_loss: 255.2693 - kl_loss: 3.9774\n",
      "Epoch 28/100\n",
      "547/547 [==============================] - 53s 96ms/step - loss: 259.0692 - reconstruction_loss: 255.0976 - kl_loss: 3.9716\n",
      "Epoch 29/100\n",
      "547/547 [==============================] - 55s 101ms/step - loss: 259.0142 - reconstruction_loss: 255.0432 - kl_loss: 3.9710\n",
      "Epoch 30/100\n",
      "547/547 [==============================] - 54s 98ms/step - loss: 258.6911 - reconstruction_loss: 254.7281 - kl_loss: 3.9630\n",
      "Epoch 31/100\n",
      "547/547 [==============================] - 52s 94ms/step - loss: 258.5791 - reconstruction_loss: 254.6124 - kl_loss: 3.9666\n",
      "Epoch 32/100\n",
      "547/547 [==============================] - 47s 86ms/step - loss: 258.5402 - reconstruction_loss: 254.5683 - kl_loss: 3.9719\n",
      "Epoch 33/100\n",
      "547/547 [==============================] - 47s 87ms/step - loss: 258.5006 - reconstruction_loss: 254.5354 - kl_loss: 3.9652\n",
      "Epoch 34/100\n",
      "547/547 [==============================] - 48s 88ms/step - loss: 258.1692 - reconstruction_loss: 254.1905 - kl_loss: 3.9788\n",
      "Epoch 35/100\n",
      "547/547 [==============================] - 48s 87ms/step - loss: 258.0297 - reconstruction_loss: 254.0587 - kl_loss: 3.9710\n",
      "Epoch 36/100\n",
      "547/547 [==============================] - 48s 87ms/step - loss: 257.9671 - reconstruction_loss: 253.9979 - kl_loss: 3.9693\n",
      "Epoch 37/100\n",
      "547/547 [==============================] - 6755s 12s/step - loss: 257.9547 - reconstruction_loss: 253.9798 - kl_loss: 3.9749\n",
      "Epoch 38/100\n",
      "474/547 [========================>.....] - ETA: 7s - loss: 257.9099 - reconstruction_loss: 253.9391 - kl_loss: 3.9708"
     ]
    }
   ],
   "source": [
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(mnist_clothes, epochs=100, batch_size=128)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_latent(encoder, decoder):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    n = 30\n",
    "    digit_size = 28\n",
    "    scale = 2.0\n",
    "    figsize = 15\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range + 1\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "plot_latent(vae.get_encoder(), vae.get_decoder())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def plot_label_clusters(encoder, data, labels):\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = encoder.predict(data)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "plot_label_clusters(encoder, x_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}